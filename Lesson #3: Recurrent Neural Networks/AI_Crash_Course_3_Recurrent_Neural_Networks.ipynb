{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AI Crash Course #3: Recurrent Neural Networks.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/QuantumTCode/FIRST-AI-Crash-Course/blob/master/Lesson%20%233%3A%20Recurrent%20Neural%20Networks/AI_Crash_Course_3_Recurrent_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "B7H7G2qU8S0v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# FIRST AI Crash Course: Recurrent Neural Networks"
      ]
    },
    {
      "metadata": {
        "id": "rHjO2OEV8Wxn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Step 0: Import Necessary Libraries"
      ]
    },
    {
      "metadata": {
        "id": "SyQmMSq58Nho",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Pandas is a data processing library\n",
        "import pandas as pd\n",
        "\n",
        "#NumPy is mathematical library\n",
        "import numpy as np\n",
        "\n",
        "# Data visualization\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# and TensorFlow is the backbone of Keras, which is the Neural Network Library we will be using\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# Splitting Data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pathlib"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "cmbRK02T8eEd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Let's Begin! All comments are where we will be working to fill in the code in real-time, they're supposed to be blank.\n",
        "\n",
        "A filled-out copy will be posted to the GitHub once we complete it in the workshop.\n"
      ]
    },
    {
      "metadata": {
        "id": "_namm8rgKhkS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# download data from GitHub\n",
        "!wget https://github.com/QuantumTCode/FIRST-AI-Crash-Course/raw/master/Lesson%20%233:%20Recurrent%20Neural%20Networks/imbd_test_X.csv\n",
        "!wget https://github.com/QuantumTCode/FIRST-AI-Crash-Course/raw/master/Lesson%20%233:%20Recurrent%20Neural%20Networks/imbd_train.csv.zip && unzip imbd_train.csv.zip && rm imbd_train.csv.zip && rm -rf __MACOSX"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_-uloV5XNB7s",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# load in data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HhceE3MBdzA8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# text preprocessing functions\n",
        "\n",
        "import re\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\")) \n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s]','',text, re.UNICODE)\n",
        "    text = text.lower()\n",
        "    text = [lemmatizer.lemmatize(token) for token in text.split(\" \")]\n",
        "    text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
        "    text = [word for word in text if not word in stop_words]\n",
        "    text = \" \".join(text)\n",
        "    return text\n",
        "\n",
        "train['review'] = train.review.apply(lambda x: clean_text(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "mK7URlrINZwl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# tokenizer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "glbD8855PsDn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# pad sequences"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "irdNu0p3M77P",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# split train and val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xHzrhbfxQAQ4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# construct model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LOdsnctlQndL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# build model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CivbZefeQoE2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#summarize model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r1GoX41vQ2Jp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Keras callbacks\n",
        "\n",
        "# Prints a dot for every epoch, just easier to keep track of training\n",
        "class PrintDot(keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs):\n",
        "    if epoch % 100 == 0: print('')\n",
        "    print('.', end='')\n",
        "    \n",
        "# Early stopping\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lrjz8gYYQ5yU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# train model\n",
        "EPOCHS = 10\n",
        "batch_size = 1024\n",
        "\n",
        "history = model.fit(train_X, train_Y,\n",
        "          batch_size=batch_size,\n",
        "          epochs=EPOCHS,\n",
        "          verbose=0,\n",
        "          validation_data=(val_X, val_Y),\n",
        "          callbacks=[PrintDot()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1LNJV32Ie3vM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# evaluate model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dyh3-B2Ne7K3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# check history\n",
        "\n",
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SEu24VwifAHC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Plot history of model function\n",
        "\n",
        "def plot_history(history):\n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "  \n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.plot(hist['epoch'], hist['acc'],\n",
        "           label='Train acc')\n",
        "  plt.plot(hist['epoch'], hist['val_acc'],\n",
        "           label = 'Val acc')\n",
        "  plt.ylim([0,1])\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HRdyNdV0fD8j",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# plot acc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "H5x59e7jflWL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# print scores \n",
        "\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PJY9DbkXQ_zt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# preprocess test text\n",
        "\n",
        "test_X = pd.read_csv(\"imbd_test_X.csv\",header=None)\n",
        "test_X.rename(columns={0:'review'}, inplace=True)\n",
        "\n",
        "test_X['review'] = test_X.review.apply(lambda x: clean_text(x))\n",
        "tokenized_test = tokenizer.texts_to_sequences(test_X['review'])\n",
        "test_X = pad_sequences(tokenized_test, maxlen=maxlen)\n",
        "\n",
        "#conduct predictions and compile submission\n",
        "\n",
        "predictions = np.round(model.predict(test_X)).astype(int)\n",
        "submission = pd.DataFrame(data=predictions, columns=['sentiment'])\n",
        "submission.to_csv(\"submission.csv\",index_label=\"index\")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}